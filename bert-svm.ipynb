{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "import warnings\n",
    "import math\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"TraningSet(postLabel_1Label_2).csv\", sep=',',engine='python')\n",
    "#dataset = pd.read_csv(\"Traningset-TFND_toxicity_features_new(label1_label2).csv\", sep='\\t',engine='python')\n",
    "#dataset.Stance = pd.Categorical(pd.factorize(dataset.Stance)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The U.S. CDC quietly updated their numbers in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Social media posts shared thousands of times a...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The CDC updated the COVID-19 number to admit t...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Either masks work or they donâ€™t; if masks wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The RT-PCR test for the virus that causes COVI...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  label_1  label_2\n",
       "0  The U.S. CDC quietly updated their numbers in ...        1    False\n",
       "1  Social media posts shared thousands of times a...        0    False\n",
       "2  The CDC updated the COVID-19 number to admit t...        0    False\n",
       "3  Either masks work or they donâ€™t; if masks wo...        1    False\n",
       "4  The RT-PCR test for the virus that causes COVI...        1    False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"TestSet(postLabel_1Label_2).csv\", sep=',',engine='python')\n",
    "#test_dataset.Stance = pd.Categorical(pd.factorize(test_dataset.Stance)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_text = []\\nfor i in range(len(dataset[\\'Tweet\\'])):\\n    train_text.append(dataset[\\'Target\\'][i] + \" \"+ dataset[\\'Tweet\\'][i])\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_text = []\n",
    "for i in range(len(dataset['Tweet'])):\n",
    "    train_text.append(dataset['Target'][i] + \" \"+ dataset['Tweet'][i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_text = []\\nfor i in range(len(test_dataset[\\'Tweet\\'])):\\n    test_text.append(test_dataset[\\'Target\\'][i] + \" \"+ test_dataset[\\'Tweet\\'][i])\\n    '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''test_text = []\n",
    "for i in range(len(test_dataset['Tweet'])):\n",
    "    test_text.append(test_dataset['Target'][i] + \" \"+ test_dataset['Tweet'][i])\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bert_features(dataset,filename):\n",
    "    bertFile = open(filename,\"w\")\n",
    "    for i in range(len(dataset)):\n",
    "        encoding = tokenizer.encode_plus(\n",
    "          dataset[i],\n",
    "          max_length=38,\n",
    "          add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "          return_token_type_ids=False,\n",
    "          pad_to_max_length=True,\n",
    "          return_attention_mask=True,\n",
    "          truncation = True,\n",
    "          return_tensors='pt',  # Return PyTorch tensors\n",
    "        )\n",
    "        #print(encoding)\n",
    "        last_hidden_state, pooled_output = bert_model(\n",
    "          input_ids=encoding['input_ids'],\n",
    "          attention_mask=encoding['attention_mask']\n",
    "        )\n",
    "        bert_rep = (pooled_output.flatten().detach().numpy())\n",
    "        #print(len(bert_rep))\n",
    "        #print(bert_rep)\n",
    "        for _ in range(len(bert_rep)-1):\n",
    "            bertFile.write(repr(bert_rep[_])+\",\")\n",
    "        bertFile.write(repr(bert_rep[767])+\"\\n\")\n",
    "    bertFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_bert_features(dataset['news'],\"bert_representation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bert_dataset = pd.read_csv(\"bert_representation.csv\", sep=',',engine='python',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_bert_features(test_dataset['news'],\"test_bert_representation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "target_words = set()\n",
    "for i in range(len(dataset['news'])):\n",
    "    nltk_tokens = nltk.word_tokenize(dataset['news'][i].lower())\n",
    "    for tok in nltk_tokens:\n",
    "        target_words.add(tok)\n",
    "\n",
    "target_words.remove(\"a\")\n",
    "target_words.remove(\"is\")\n",
    "target_words.remove(\"of\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "target2id = {w:i for i,w in enumerate(target_words)}\n",
    "def create_target_vector(dataset):\n",
    "    target_dataset = []\n",
    "    for target in dataset:\n",
    "        target_vector = np.zeros(len(target2id))\n",
    "        nltk_tokens = nltk.word_tokenize(target.lower())\n",
    "        for tok in nltk_tokens:\n",
    "            if tok in target2id:\n",
    "                target_vector[target2id[tok]]=1\n",
    "        target_dataset.append(target_vector)\n",
    "    return(target_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_vectors = (create_target_vector(dataset['news']))\n",
    "test_target_vectors = (create_target_vector(test_dataset['news']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_dataset = bert_dataset.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "724\n"
     ]
    }
   ],
   "source": [
    "print(len(bert_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , ..., -0.74333525,\n",
       "       -0.66287977,  0.55816853])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_target_train_ds  = []\n",
    "for i in range(len(dataset['label_1'])):\n",
    "    \n",
    "    bert_target_vector = (np.concatenate((np.array(train_target_vectors[i]),(bert_dataset[i])),axis=None))\n",
    "    bert_target_train_ds.append(bert_target_vector)\n",
    "bert_target_train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_target_test_ds  = []\n",
    "test_bert_dataset = pd.read_csv(\"test_bert_representation.csv\", sep=',',engine='python',header=None)\n",
    "test_bert_dataset = test_bert_dataset.to_numpy()\n",
    "for i in range(len(test_dataset['label_1'])):   \n",
    "    bert_target_vector = (np.concatenate((np.array(test_target_vectors[i]),np.array(test_bert_dataset[i])),axis=None))\n",
    "    bert_target_test_ds.append(bert_target_vector)\n",
    "bert_target_test_ds[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(bert_target_train_ds, dataset['label_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_pred = clf.predict(bert_target_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103  24]\n",
      " [ 49  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6776    0.8110    0.7384       127\n",
      "           1     0.4667    0.3000    0.3652        70\n",
      "\n",
      "    accuracy                         0.6294       197\n",
      "   macro avg     0.5721    0.5555    0.5518       197\n",
      "weighted avg     0.6027    0.6294    0.6058       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_test_pred = clf.predict(bert_target_test_ds)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(test_dataset['label_1'],svm_test_pred))\n",
    "print(classification_report(test_dataset['label_1'],svm_test_pred,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[521   2]\n",
      " [  1 200]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9981    0.9962    0.9971       523\n",
      "           1     0.9901    0.9950    0.9926       201\n",
      "\n",
      "    accuracy                         0.9959       724\n",
      "   macro avg     0.9941    0.9956    0.9948       724\n",
      "weighted avg     0.9959    0.9959    0.9959       724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_train_pred = clf.predict(bert_target_train_ds)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(dataset['label_1'],svm_train_pred))\n",
    "print(classification_report(dataset['label_1'],svm_train_pred,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "clf = GridSearchCV(SVC(), params_grid, cv=5)\n",
    "clf.fit(bert_dataset, dataset['label_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(test_bert_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       127\n",
      "           1       1.00      0.01      0.03        70\n",
      "\n",
      "    accuracy                           0.65       197\n",
      "   macro avg       0.82      0.51      0.41       197\n",
      "weighted avg       0.77      0.65      0.52       197\n",
      "\n",
      "f1_score: 0.649746192893401\n",
      "f2_score: 0.649746192893401\n",
      "f0.5_score: 0.649746192893401\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "print(classification_report(test_dataset['label_1'],pred))\n",
    "\n",
    "print(\"f1_score:\",f1_score(test_dataset['label_1'], pred.round(), average='micro'))\n",
    "print(\"f2_score:\",fbeta_score(test_dataset['label_1'],pred.round(), beta=2,average='micro'))\n",
    "print(\"f0.5_score:\",fbeta_score(test_dataset['label_1'], pred.round(), beta=0.5,average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier().fit(bert_target_train_ds, dataset['label_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6513    1.0000    0.7888       127\n",
      "           1     1.0000    0.0286    0.0556        70\n",
      "\n",
      "    accuracy                         0.6548       197\n",
      "   macro avg     0.8256    0.5143    0.4222       197\n",
      "weighted avg     0.7752    0.6548    0.5283       197\n",
      "\n",
      "f1_score: 0.6548223350253807\n",
      "f2_score: 0.6548223350253807\n",
      "f0.5_score: 0.6548223350253807\n"
     ]
    }
   ],
   "source": [
    "rf_pred = clf.predict(bert_target_test_ds)\n",
    "print(classification_report(test_dataset['label_1'],rf_pred,digits=4))\n",
    "\n",
    "print(\"f1_score:\",f1_score(test_dataset['label_1'], rf_pred.round(), average='micro'))\n",
    "print(\"f2_score:\",fbeta_score(test_dataset['label_1'],rf_pred.round(), beta=2,average='micro'))\n",
    "print(\"f0.5_score:\",fbeta_score(test_dataset['label_1'], rf_pred.round(), beta=0.5,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*************************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-ad9c8db73726>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'svm_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(svm_pred[0])\n",
    "print(rf_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nn_pred = pd.read_csv(\"bert-NN.csv\", engine='python',header=None)\n",
    "cnn_pred = pd.read_csv(\"bert-CNN.csv\", engine='python',header=None)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nn_pred[0][0]\n",
    "cnn_pred[0][0]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''mv_pred = []\n",
    "for i in range(len(rf_pred)):\n",
    "    voting = [0,0,0]\n",
    "    voting[svm_pred[i]] = 1+voting[svm_pred[i]]\n",
    "    voting[rf_pred[i]] = 1+voting[rf_pred[i]]\n",
    "    voting[nn_pred[0][i]] = 1+voting[nn_pred[0][i]]\n",
    "    voting[cnn_pred[0][i]] = 1+voting[cnn_pred[0][i]]\n",
    "       \n",
    "    mv_pred.append(voting.index(max(voting)))\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "print(classification_report(test_dataset['Stance'],mv_pred))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
