{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import training dataset:\n",
    "#dataset = pd.read_csv(\"C:\\\\Users\\mudasirw\\Desktop\\RESEARCH @N T N U -JULY 2019\\Sexual predator detection and Emotion Differences using PAN dataset\\DATASETS\\mmmmCOMPLETE_TRAINING_dataset(cBoW+ emotion-170729).csv\")\n",
    "dataset = pd.read_csv(\"TFND_toxicity_features_new(label1_label2).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    650\n",
       "1    272\n",
       "Name: label_1, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count the frequency of categorical data in a column in pandas\n",
    "dataset['label_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>Severe_toxicity</th>\n",
       "      <th>Obscene</th>\n",
       "      <th>Identity_attack</th>\n",
       "      <th>Insult</th>\n",
       "      <th>Threat</th>\n",
       "      <th>Sexual_explicit</th>\n",
       "      <th>total_toxicity</th>\n",
       "      <th>toxicity+non_toxicity</th>\n",
       "      <th>non_toxicity_score</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000299</td>\n",
       "      <td>6.565720</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>6.788591</td>\n",
       "      <td>4.186364</td>\n",
       "      <td>17.541998</td>\n",
       "      <td>31</td>\n",
       "      <td>13.458002</td>\n",
       "      <td>1</td>\n",
       "      <td>Fake</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000426</td>\n",
       "      <td>3.562209</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>4.952937</td>\n",
       "      <td>3.178688</td>\n",
       "      <td>11.694682</td>\n",
       "      <td>31</td>\n",
       "      <td>19.305318</td>\n",
       "      <td>0</td>\n",
       "      <td>Fake</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000491</td>\n",
       "      <td>2.089846</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>7.492199</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>3.276651</td>\n",
       "      <td>2.164755</td>\n",
       "      <td>15.024235</td>\n",
       "      <td>31</td>\n",
       "      <td>15.975765</td>\n",
       "      <td>0</td>\n",
       "      <td>Fake</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000358</td>\n",
       "      <td>3.127737</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>9.284008</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>4.161154</td>\n",
       "      <td>2.600842</td>\n",
       "      <td>19.174432</td>\n",
       "      <td>31</td>\n",
       "      <td>11.825568</td>\n",
       "      <td>1</td>\n",
       "      <td>Fake</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000627</td>\n",
       "      <td>3.971006</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>9.670234</td>\n",
       "      <td>4.232443</td>\n",
       "      <td>17.874843</td>\n",
       "      <td>31</td>\n",
       "      <td>13.125157</td>\n",
       "      <td>1</td>\n",
       "      <td>Fake</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Toxicity  Severe_toxicity   Obscene  Identity_attack    Insult    Threat  \\\n",
       "0  0.000299         6.565720  0.000458         0.000163  0.000402  6.788591   \n",
       "1  0.000426         3.562209  0.000158         0.000124  0.000141  4.952937   \n",
       "2  0.000491         2.089846  0.000116         7.492199  0.000177  3.276651   \n",
       "3  0.000358         3.127737  0.000165         9.284008  0.000167  4.161154   \n",
       "4  0.000627         3.971006  0.000207         0.000154  0.000171  9.670234   \n",
       "\n",
       "   Sexual_explicit  total_toxicity  toxicity+non_toxicity  non_toxicity_score  \\\n",
       "0         4.186364       17.541998                     31           13.458002   \n",
       "1         3.178688       11.694682                     31           19.305318   \n",
       "2         2.164755       15.024235                     31           15.975765   \n",
       "3         2.600842       19.174432                     31           11.825568   \n",
       "4         4.232443       17.874843                     31           13.125157   \n",
       "\n",
       "   label_1 label_2  Unnamed: 12  \n",
       "0        1    Fake          NaN  \n",
       "1        0    Fake          NaN  \n",
       "2        0    Fake          NaN  \n",
       "3        1    Fake          NaN  \n",
       "4        1    Fake          NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_1\n"
     ]
    }
   ],
   "source": [
    "print(dataset.columns[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing Data For Training\n",
    "#divide data into attributes and labels:\n",
    "\n",
    "#------------------- cBoW fearures\n",
    "\n",
    "#X = dataset.iloc[:, 0:532].values\n",
    "#y = dataset.iloc[:, 532].values\n",
    "\n",
    "\n",
    "# cBoW + Emotion fearures\n",
    "X = dataset.iloc[:, 0:6].values\n",
    "y = dataset.iloc[:, 10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide  training and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training RF model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix \n",
      " [[51 18]\n",
      " [13 11]]\n",
      "recall_score:  0.4583333333333333\n",
      "\n",
      " classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77        69\n",
      "           1       0.38      0.46      0.42        24\n",
      "\n",
      "    accuracy                           0.67        93\n",
      "   macro avg       0.59      0.60      0.59        93\n",
      "weighted avg       0.69      0.67      0.68        93\n",
      "\n",
      "accuracy_score:  0.6666666666666666\n",
      "f1_score: 0.5910058164278621\n",
      "f2_score: 0.44\n",
      "f0.5_score: 0.39285714285714285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Confusion matrix \\n\",confusion_matrix(y_test,y_pred.round()))\n",
    "#print(\"accuracy_score: \",accuracy_score(y_test, y_pred.round()))\n",
    "print(\"recall_score: \",recall_score(y_test, y_pred.round()))\n",
    "print(\"\\n classification_report \\n\",classification_report(y_test,y_pred.round()))\n",
    "print(\"accuracy_score: \",accuracy_score(y_test, y_pred.round()))\n",
    "print(\"f1_score:\",f1_score(y_test, y_pred.round(),average='macro'))\n",
    "print(\"f2_score:\",fbeta_score(y_test, y_pred.round(), beta=2))\n",
    "print(\"f0.5_score:\",fbeta_score(y_test, y_pred.round(), beta=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide  training and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "svm_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9247311827956989\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn import svm\\nclf = svm.SVC(kernel='linear')\\nclf.fit(bert_target_train_ds, dataset['label_1'])\\n\\nsvm_pred = clf.predict(bert_target_test_ds)\\n\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(bert_target_train_ds, dataset['label_1'])\n",
    "\n",
    "svm_pred = clf.predict(bert_target_test_ds)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix \n",
      " [[65  4]\n",
      " [ 3 21]]\n",
      "recall_score:  0.875\n",
      "\n",
      " classification_report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95        69\n",
      "           1       0.84      0.88      0.86        24\n",
      "\n",
      "    accuracy                           0.92        93\n",
      "   macro avg       0.90      0.91      0.90        93\n",
      "weighted avg       0.93      0.92      0.93        93\n",
      "\n",
      "accuracy_score:  0.9247311827956989\n",
      "f1_score: 0.8571428571428572\n",
      "f2_score: 0.8677685950413225\n",
      "f0.5_score: 0.8467741935483872\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion matrix \\n\",confusion_matrix(y_test,svm_pred.round()))\n",
    "#print(\"accuracy_score: \",accuracy_score(y_test, y_pred.round()))\n",
    "print(\"recall_score: \",recall_score(y_test, svm_pred.round()))\n",
    "print(\"\\n classification_report \\n\",classification_report(y_test,svm_pred.round()))\n",
    "print(\"accuracy_score: \",accuracy_score(y_test, svm_pred.round()))\n",
    "print(\"f1_score:\",f1_score(y_test, svm_pred.round()))\n",
    "print(\"f2_score:\",fbeta_score(y_test, svm_pred.round(), beta=2))\n",
    "print(\"f0.5_score:\",fbeta_score(y_test, svm_pred.round(), beta=0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
